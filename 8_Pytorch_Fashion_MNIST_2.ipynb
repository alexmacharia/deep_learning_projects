{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP31IwGJ+F3ZtcgUFWL0bdL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexmacharia/deep_learning_projects/blob/main/8_Pytorch_Fashion_MNIST_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THSN7pAOF_3h",
        "outputId": "deeec418-1ddd-4989-d9cc-f5d691de1580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import PIL\n",
        "import numpy as np\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "print(\"GPU available: {}\".format(torch.cuda.is_available()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'"
      ],
      "metadata": {
        "id": "1YGKohqZGoIQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        # Transforms are executed in the order they are called\n",
        "        # Some transforms return color image hence the need to convert image back to grayscale\n",
        "        transforms.RandomAffine(degrees=10, translate=(0.05,0.05), shear=5),\n",
        "        transforms.ColorJitter(hue=.05, saturation=.05),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,),(0.5,)),\n",
        "\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,),(0.5,))\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "BaJGsXrjGva5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
        "                                             download=True, transform=data_transforms['train'])\n",
        "\n",
        "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
        "                                            download=True, transform=data_transforms['val'])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                         shuffle=True, num_workers=2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpTIyZTyIexo",
        "outputId": "5b1b181b-8451-406c-a951-2d039abb4a1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:14<00:00, 1778624.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 57324.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:09<00:00, 469953.56it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 16790262.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3)\n",
        "    self.conv1_bn = nn.BatchNorm2d(32)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "    self.conv2_bn = nn.BatchNorm2d(64)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(64 * 12 * 12, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "    self.dropOut = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "    x = self.dropOut(x)\n",
        "    x = self.dropOut(F.relu(self.conv2_bn(self.conv2(x))))\n",
        "\n",
        "    x = self.pool(x)\n",
        "    x = x.view(-1, 64 * 12 * 12)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.to(device)\n"
      ],
      "metadata": {
        "id": "xHeZFPbsJgJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9117800-2e96-4b04-dcfa-88d2be71ed28"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              "  (dropOut): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)"
      ],
      "metadata": {
        "id": "BrIhpdN_txNl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "\n",
        "epoch_log = []\n",
        "loss_log = []\n",
        "accuracy_log = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(f'Starting Epoch: {epoch+1}...')\n",
        "\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    inputs, labels = data\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % 100 == 99:\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for data in testloader:\n",
        "          images, labels = data\n",
        "\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          outputs = net(images)\n",
        "\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        epoch_num = epoch + 1\n",
        "        actual_loss = running_loss / 50\n",
        "        print(f'Epoch: {epoch_num}, Mini-Batches Completed: {(i+1)}, Loss: {actual_loss:.3f}, Test Accuracy = {accuracy:.3f}%')\n",
        "        running_loss = 0.0\n",
        "\n",
        "  epoch_log.append(epoch_num)\n",
        "  loss_log.append(actual_loss)\n",
        "  accuracy_log.append(accuracy)\n",
        "\n",
        "print('Finished Training')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV4CVEFZu4rW",
        "outputId": "6cedcb9d-946e-4e58-a435-5c52e972caac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Epoch: 1...\n",
            "Epoch: 1, Mini-Batches Completed: 100, Loss: 1.565, Test Accuracy = 75.290%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5IqsHz_HxkC9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}